{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron\n",
    "\n",
    "This demo shows how the sklearn <code>MLPClassifier</code> is used to build a multilayer perceptron that classifies digits from the MNIST data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.load('data/mnist/mnist_data.pkl')\n",
    "y = np.load('data/mnist/mnist_target.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_number(X,y,idx):\n",
    "    plt.imshow(X[idx].reshape(28,28), cmap=matplotlib.cm.binary, interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(\"Label:\" + str(y[idx]))\n",
    "    \n",
    "draw_number(X,y,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As usual, split the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(\"Training data set size: \" + str(X_train.shape))\n",
    "print(\"Test data set size: \" +str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Let's make 2 hidden layers of with 200 and 100 neurons, respectively\n",
    "layer_tuple = (200,100)\n",
    "# Don't forget to scale!\n",
    "std_scaler = StandardScaler()\n",
    "X_train_s = std_scaler.fit_transform(X_train)\n",
    "\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=layer_tuple, activation='logistic', tol=5e-3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_clf.fit(X_train_s, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how we did!\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "X_test_s = std_scaler.transform(X_test)\n",
    "y_pred = mlp_clf.predict(X_test_s)\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "fig_cm = plt.figure(num=2, figsize=(7,7))\n",
    "plt.matshow(cf, fignum=2, cmap=plt.cm.plasma)\n",
    "plt.show()\n",
    "print(\"More yellow is better...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at them visually...\n",
    "idxs = np.random.choice(len(y_pred), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in idxs:\n",
    "    draw_number(X_test, y_pred, i)\n",
    "    print(\"True label: \" + str(y_test[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
